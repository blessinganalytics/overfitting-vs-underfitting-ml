# Overfitting vs Underfitting Demonstration
# Author: Blessing Christopher Edet

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# Generate synthetic data
np.random.seed(42)
X = np.sort(np.random.rand(100, 1) * 6 - 3, axis=0)
y = 0.5 * X**3 - X**2 + 2 + np.random.randn(100, 1)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Degrees to demonstrate
degrees = [1, 5, 15]

plt.figure(figsize=(12, 4))

for i, degree in enumerate(degrees):
    poly = PolynomialFeatures(degree=degree)
    X_poly_train = poly.fit_transform(X_train)

    model = LinearRegression()
    model.fit(X_poly_train, y_train)

    # Prediction curve
    X_plot = np.linspace(-3, 3, 200).reshape(200, 1)
    X_plot_poly = poly.transform(X_plot)
    y_plot = model.predict(X_plot_poly)

    plt.subplot(1, 3, i + 1)
    plt.scatter(X_train, y_train)
    plt.plot(X_plot, y_plot)
    plt.title(f"Polynomial Degree {degree}")

plt.tight_layout()
plt.show()
